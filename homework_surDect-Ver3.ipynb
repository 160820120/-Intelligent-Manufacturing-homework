{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab8b7c8-05c2-45e0-b7f6-c2bf7c108073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc34164-e3f4-4448-80e6-d238c5806983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceDefectDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        img_files = os.listdir(root_dir)\n",
    "        self.defect_types = []\n",
    "        self.images = []\n",
    "        index = 0\n",
    "        for file_name in img_files:\n",
    "            defect_attrs = file_name.split(\"_\")\n",
    "            d_index = defect_labels.index(defect_attrs[0])\n",
    "            self.images.append(os.path.join(root_dir, file_name))\n",
    "            self.defect_types.append(d_index)\n",
    "            index += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def num_of_samples(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            image_path = self.images[idx]\n",
    "        else:\n",
    "            image_path = self.images[idx]\n",
    "        img = cv.imread(image_path)  # BGR order\n",
    "        h, w, c = img.shape\n",
    "        # rescale\n",
    "        img = cv.resize(img, (200, 200))\n",
    "        img = (np.float32(img) / 255.0 - 0.5) / 0.5\n",
    "        # H, W, C to C, H, W\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        sample = {'image': torch.from_numpy(img), 'defect': self.defect_types[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3f8c29-678f-4ec5-af45-99a8f63c1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_labels = [\"Cr\", \"In\", \"Pa\", \"PS\", \"RS\", \"Sc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfae787b-8a5f-49a3-a80e-ddd11e0769b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.')\n",
    "else:\n",
    "    print('CUDA is available!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b747dfe-5f9b-4dcd-a7fc-a09ea4f76d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceDefectResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurfaceDefectResNet, self).__init__()\n",
    "        # self.cnn_layers = torchvision.models.resnet34(pretrained=True)\n",
    "        self.cnn_layers = torchvision.models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.cnn_layers.fc.in_features\n",
    "        self.cnn_layers.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn_layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac809c82-5333-424f-910d-222a98567bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SurfaceDefectDataset(\"C:\\\\Users\\\\15588\\\\Desktop\\\\CLS-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d7bce7-e49d-4d18-93e7-50c2631b483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb85826-a484-41fe-813d-85d9a69fa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurfaceDefectResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279556c4-0047-415a-bf63-0bd40f02d8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9c48fa-a775-45e2-a3b2-f2829cd1ba4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tTraining Loss: 1.695910 \n",
      "epoch: 2 \tTraining Loss: 1.026149 \n",
      "epoch: 3 \tTraining Loss: 0.819585 \n",
      "epoch: 4 \tTraining Loss: 0.639185 \n",
      "epoch: 5 \tTraining Loss: 0.671258 \n",
      "epoch: 6 \tTraining Loss: 0.661767 \n",
      "epoch: 7 \tTraining Loss: 0.550541 \n",
      "epoch: 8 \tTraining Loss: 0.418405 \n",
      "epoch: 9 \tTraining Loss: 0.591079 \n",
      "epoch: 10 \tTraining Loss: 0.466920 \n",
      "epoch: 11 \tTraining Loss: 0.504816 \n",
      "epoch: 12 \tTraining Loss: 0.372199 \n",
      "epoch: 13 \tTraining Loss: 0.379214 \n",
      "epoch: 14 \tTraining Loss: 0.303750 \n",
      "epoch: 15 \tTraining Loss: 0.363544 \n",
      "epoch: 16 \tTraining Loss: 0.263973 \n",
      "epoch: 17 \tTraining Loss: 0.173828 \n",
      "epoch: 18 \tTraining Loss: 0.196624 \n",
      "epoch: 19 \tTraining Loss: 0.284809 \n",
      "epoch: 20 \tTraining Loss: 0.191728 \n",
      "epoch: 21 \tTraining Loss: 0.144083 \n",
      "epoch: 22 \tTraining Loss: 0.177652 \n",
      "epoch: 23 \tTraining Loss: 0.103162 \n",
      "epoch: 24 \tTraining Loss: 0.172535 \n",
      "epoch: 25 \tTraining Loss: 0.134895 \n",
      "epoch: 26 \tTraining Loss: 0.092519 \n",
      "epoch: 27 \tTraining Loss: 0.142904 \n",
      "epoch: 28 \tTraining Loss: 0.208205 \n",
      "epoch: 29 \tTraining Loss: 0.149648 \n",
      "epoch: 30 \tTraining Loss: 0.222899 \n",
      "epoch: 31 \tTraining Loss: 0.097126 \n",
      "epoch: 32 \tTraining Loss: 0.101207 \n",
      "epoch: 33 \tTraining Loss: 0.089366 \n",
      "epoch: 34 \tTraining Loss: 0.183787 \n",
      "epoch: 35 \tTraining Loss: 0.117928 \n",
      "epoch: 36 \tTraining Loss: 0.072522 \n",
      "epoch: 37 \tTraining Loss: 0.106603 \n",
      "epoch: 38 \tTraining Loss: 0.093799 \n",
      "epoch: 39 \tTraining Loss: 0.057271 \n",
      "epoch: 40 \tTraining Loss: 0.049425 \n",
      "epoch: 41 \tTraining Loss: 0.062792 \n",
      "epoch: 42 \tTraining Loss: 0.038766 \n",
      "epoch: 43 \tTraining Loss: 0.035812 \n",
      "epoch: 44 \tTraining Loss: 0.032584 \n",
      "epoch: 45 \tTraining Loss: 0.022507 \n",
      "epoch: 46 \tTraining Loss: 0.065830 \n",
      "epoch: 47 \tTraining Loss: 0.056948 \n",
      "epoch: 48 \tTraining Loss: 0.066632 \n",
      "epoch: 49 \tTraining Loss: 0.057529 \n",
      "epoch: 50 \tTraining Loss: 0.035365 \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    index = 0\n",
    "    train_loss = 0\n",
    "    for i_batch, sample_batched in enumerate(train_data_loader):\n",
    "        images_batch, label_batch = sample_batched['image'], sample_batched['defect']\n",
    "        if train_on_gpu:\n",
    "            model.cuda()\n",
    "            images_batch, label_batch= images_batch.cuda(), label_batch.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        m_label_out_ = model(images_batch)\n",
    "        label_batch = label_batch.long()\n",
    "        loss = cross_loss(m_label_out_, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        index += 1\n",
    "    print('epoch: {} \\tTraining Loss: {:.6f} '.format(epoch+1, train_loss/index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d63517-097b-4fb2-b573-9417ced3e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SurfaceDefectDataset(\"C:\\\\Users\\\\15588\\\\Desktop\\\\CLS-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b664636-495c-426c-a1f2-097eb8d2d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e849195-94f9-4782-a88b-5bc02c4f31cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Cr\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：In\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Pa\n",
      "预测当前图片中的缺陷为：Pa\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：In\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：PS\n",
      "预测当前图片中的缺陷为：PS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：Cr\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：RS\n",
      "预测当前图片中的缺陷为：RS\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n",
      "当前图片中的缺陷为：Sc\n",
      "预测当前图片中的缺陷为：Sc\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "for i_batch, sample_batched in enumerate(test_data_loader):\n",
    "    images_batch, label_batch = sample_batched['image'], sample_batched['defect']\n",
    "    true_label = defect_labels[label_batch.item()]\n",
    "    print(\"当前图片中的缺陷为：\" + str(true_label))\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "        images_batch, label_batch= images_batch.cuda(), label_batch.cuda()\n",
    "    output = model(images_batch)\n",
    "    output = output.squeeze(0)\n",
    "    output = softmax(output)\n",
    "    output_list = output.tolist()\n",
    "    index = output_list.index(max(output_list))\n",
    "    predict_label = defect_labels[index]\n",
    "    print(\"预测当前图片中的缺陷为：\" + str(predict_label))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901c290-d647-4f2c-89be-fd961a2cb590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
